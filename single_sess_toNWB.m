% Replicating PyNWB version of converting Steinmetz et. al dataset to
% NWB format in MatNWB. Source: https://github.com/SteinmetzLab/dataToNWB

% add subject information
subject = types.core.Subject('age', 'P77D', ...
               'genotype', 'tetO-G6s x CaMK-tTA', ...
               'sex', 'F', ...
               'species', 'Mus musculus', ...
               'description', 'strain: C57Bl6/J');

% create nwb file
nwb_file = NwbFile(...
    'session_description', {'Neuropixels recording during visual '
                            'discrimination in awake mice.'}, ...
    'identifier', 'Cori_2016-12-14', ...
    'session_start_time', datetime(2016, 12, 14, 12, 0, 0), ...
    'general_institution', 'University College London', ...
    'general_lab', 'The Carandini & Harris Lab', ...
    'general_subject', subject, ...
    'general_experimenter', 'Nick Steinmetz', ...
    'general_experiment_description', {'Large-scale Neuropixels recordings'
                                       'across brain regions of mice '
                                       'during a head-fixed visual '
                                       'discrimination task. '}, ...
    'general_related_publications', 'DOI 10.1038/s41586-019-1787-x', ...
    'general_keywords', ['Neural coding', 'Neuropixels', 'mouse', ...
                        'brain-wide', 'vision', 'visual discrimination', ...
                        'electrophysiology']);

% create processing module
behavior_mod = types.core.ProcessingModule('description', 'behavior module');
nwb_file.processing.set('behavior', behavior_mod);

behavior_mod = Eye(behavior_mod);
behavior_mod = Face(behavior_mod);
lp_ts = LickPiezo();
nwb_file.acquisition.set('LickPiezo', lp_ts);
behavior_mod = LickTimes(behavior_mod);
spont_ti = Spontaneous();
nwb_file.intervals.set('spontaneous', spont_ti);
wheel_ts = Wheel();
nwb_file.acquisition.set('WheelTimes', wheel_ts);
behavior_mod = WheelMoves(behavior_mod);
trials = TrialTable();
nwb_file.intervals_trials = trials;
sp_noise = SparseNoise();
nwb_file.stimulus_presentation.set('receptive_field_mapping_sparse_noise', sp_noise);
[beep_ts, click_ts, pass_l, pass_r, pass_white] = PassiveStim();
nwb_file.stimulus_presentation.set('passive_beeps', beep_ts);
nwb_file.stimulus_presentation.set('passive_click_times', click_ts);
nwb_file.stimulus_presentation.set('passive_left_contrast', pass_l);
nwb_file.stimulus_presentation.set('passive_right_contrast', pass_r);
nwb_file.stimulus_presentation.set('passive_white_noise', pass_white);

[nwb_file, electrode_groups] = ElectrodeTable(nwb_file);
%nwb_file = ClustersSpikes(nwb_file, electrode_groups);

nwbExport(nwb_file, 'test_one_session.nwb');

function rate = Rate(timestamps)
    % calculate rate
    rate = (timestamps(2, 2) - timestamps(1, 2)) / (timestamps(2, 1));
end

function behavior_mod = Eye(behavior_mod)
    % function to add eye position and pupil tracking to processing module

    eye_timestamps = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_eye.timestamps.npy');
    eye_area = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_eye.area.npy');
    eye_xy_pos = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_eye.xyPos.npy');

    pupil = types.core.TimeSeries('timestamps',  eye_timestamps(:, 2), ...
                 'data', eye_area', ...
                 'data_unit', 'arb. unit', ...
                 'description', {'Features extracted from the '
                                 'video of the right eye.'}, ...
                 'comments', {'The area of the pupil extracted '
                 'with DeepLabCut. Note that '
                 'it is relatively very small during the discrimination task '
                 'and during the passive replay because the three screens are '
                 'medium-grey at this time and black elsewhere - so the much '
                 'brighter overall luminance levels lead to relatively '
                 'constricted pupils.'});

    eye_xy = types.core.TimeSeries('timestamps',eye_timestamps(:, 2), ...
                'data', eye_xy_pos, ...
                'data_unit', 'arb. unit', ...
                'description', {'Features extracted from the video '
                                'of the right eye.'}, ...
                'comments', {'The 2D position of the center of the pupil '
                             'in the video frame. This is not registered '
                             'to degrees visual angle, but '
                             'could be used to detect saccades or '
                             'other changes in eye position.'});
    pupil_track = types.core.PupilTracking('timeseries', [pupil, eye_xy]);
    behavior_mod.nwbdatainterface.set(...
                    'PupilTracking', pupil_track);

end

function behavior_mod = Face(behavior_mod)
    % Add face energy behavior data to behavior processing module
    face_motion_energy = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_face.motionEnergy.npy');
    face_timestamps = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_face.timestamps.npy');
    face_rate = Rate(face_timestamps);
    face_energy = types.core.TimeSeries(...
        'data', face_motion_energy', ...
        'data_unit', 'arb. unit', ...
        'starting_time', face_timestamps(1, 2), ...
        'starting_time_rate', face_rate, ...
        'description', {'Features extracted from the video of the '
                        'frontal aspect of the subject, including the '
                        'subject face and forearms.'}, ...
        'comments', {'The integrated motion energy across the whole frame'
                     ', i.e. sum( (thisFrame-lastFrame)^2 ). '
                     'Some smoothing is applied before this operation.'});
    face_interface = types.core.BehavioralTimeSeries('timeseries', face_energy);
    behavior_mod.nwbdatainterface.set(...
                    'BehavioralTimeSeries', face_interface);
end

function lp_timeseries = LickPiezo()
    % add lick piezo to nwb acquisition
    lp_raw = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_lickPiezo.raw.npy');
    lp_timestamps = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_lickPiezo.timestamps.npy');
    lp_rate = Rate(lp_timestamps);
    lp_timeseries = types.core.TimeSeries(...
                'starting_time', lp_timestamps(1, 2), ...
                'starting_time_rate', lp_rate, ...
                'data', lp_raw', ...
                'data_unit', 'V', ...
                'description', {'Voltage values from a thin-film piezo connected to the '
                    'lick spout, so that values are proportional to deflection '
                    'of the spout and licks can be detected as peaks of the signal.'});
end

function behavior_mod = LickTimes(behavior_mod)
    % add lick behavioral events to behavior processing module
    lick_timestamps = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_licks.times.npy');
    lick_data = ones(length(lick_timestamps), 1);
    lick_ts = types.core.TimeSeries(...
                    'timestamps', lick_timestamps', ...
                    'data', lick_data, ...
                    'data_unit', '', ...
                    'description', {'Extracted times of licks, '
                                    'from the lickPiezo signal.'});
    lick_behavior = types.core.BehavioralEvents('timeseries', lick_ts);
    behavior_mod.nwbdatainterface.set(...
                    'BehavioralEvents', lick_behavior);
end

function spont_ti = Spontaneous()
    % add spontaneous intervals to acquisition
    spont = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_spontaneous.intervals.npy');
    start_time = spont(:, 1);
    stop_time = spont(:, 2);

    spont_ti = types.core.TimeIntervals(...
                'colnames', {'start_time', 'stop_time'}, ...
                'id', types.hdmf_common.ElementIdentifiers('data', 0:length(spont(:, 1))-1), ...
                'description', {'Intervals of sufficient duration when nothing '
                                'else is going on (no task or stimulus presentation'}, ...
                'start_time', types.hdmf_common.VectorData('data', ...
                    start_time, 'description', 'this is start time'), ...
                'stop_time', types.hdmf_common.VectorData('data', ...
                    stop_time, 'description','this is stop time'));
end

function wheel_ts = Wheel()
    % add wheel position to nwb.acquisition
    wheel_pos = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_wheel.position.npy');
    wheel_ts = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_wheel.timestamps.npy');
    wheel_rate = Rate(wheel_ts);

    wheel_ts = types.core.TimeSeries(...
                'starting_time', wheel_ts(1, 2), ...
                'starting_time_rate', wheel_rate, ...
                'data', wheel_pos', ...
                'data_unit', 'mm', ...
                'data_conversion', 0.135, ...
                'description', {'The position reading of the rotary encoder attached to '
                                'the rubber wheel that the mouse pushes left and right '
                                'with his forelimbs.'}, ...
                'comments', {'The wheel has radius 31 mm and 1440 ticks per revolution, '
                             'so multiply by 2*pi*r/tpr=0.135 to convert to millimeters. '
                             'Positive velocity (increasing numbers) correspond to clockwise '
                             'turns (if looking at the wheel from behind the mouse), i.e. '
                             'turns that are in the correct direction for stimuli presented '
                             'to the left. Likewise negative velocity corresponds to right choices.'});
end

function behavior_mod = WheelMoves(behavior_mod)
    % add wheel moves to BehavioralEpochs to behavior module
    wheel_moves_type = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_wheelMoves.type.npy');
    wheel_moves_int = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_wheelMoves.intervals.npy');
    wheel_moves_int = ceil(wheel_moves_int(:));

    wheel_moves_is = types.core.IntervalSeries(...
                        'timestamps', wheel_moves_int, ...
                        'data', wheel_moves_type', ...
                        'description', {'Detected wheel movements.'}, ...
                        'comments', {'0 for flinches or otherwise unclassified movements, '
                                     '1 for left/clockwise turns, 2 for right/counter-clockwise '
                                     'turns (where again "left" means "would be the correct '
                                     'direction for a stimulus presented on the left). A detected '
                                     'movement is counted as left or right only if it was '
                                     'sufficient amplitude that it would have registered a correct '
                                     'response (and possibly did), within a minimum amount of time '
                                     'from the start of the movement. Movements failing those '
                                     'criteria are flinch/unclassified type.'});
    wheel_moves_beh = types.core.BehavioralEpochs('intervalseries', wheel_moves_is);
    behavior_mod.nwbdatainterface.set(...
                    'BehavioralEpochs', wheel_moves_beh);
end

function trials = TrialTable()
    % create trial table to add to nwb

    included = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.included.npy');
    fb_type = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.feedbackType.npy');
    fb_type = ceil(fb_type);
    fb_time = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.feedback_times.npy');
    go_cue = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.goCue_times.npy');
    trial_intervals = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.intervals.npy');
    rep_num = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.repNum.npy');
    response_choice = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.response_choice.npy');
    response_times = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.response_times.npy');
    visual_left = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.visualStim_contrastLeft.npy');
    visual_right = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.visualStim_contrastRight.npy');
    visual_times = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_trials.visualStim_times.npy');

    start_time = trial_intervals(:, 1);
    stop_time = trial_intervals(:, 2);

    % add trials
    trials = types.core.TimeIntervals(...
        'colnames', {'start_time', 'stop_time', 'included', 'go_cue'}, ...
        'description', 'trial table for behavioral trials', ...
        'id', types.hdmf_common.ElementIdentifiers('data', 0:length(included)-1), ...
        'start_time', types.hdmf_common.VectorData('data', ...
               start_time, 'description', 'this is start time'), ...
        'stop_time', types.hdmf_common.VectorData('data', ...
               stop_time, 'description','this is stop time'), ...
        'included', types.hdmf_common.VectorData('data', included(:), ...
                        'description',{'Importantly, while this '
                            'variable gives inclusion criteria according '
                            'to the definition of disengagement '
                            '(see manuscript Methods), it does '
                            'not give inclusion criteria based on the '
                            'time of response, as used '
                            'for most analyses in the paper.'}), ...
         'go_cue', types.hdmf_common.VectorData('data', go_cue(:), ...
                        'description',{'The goCue is referred to as the '
                            'auditory tone cue in the manuscript.'}), ...
         'visual_stimulus_time', types.hdmf_common.VectorData('data', visual_times(:), ...
                        'description',{'Times are relative to the same time'
                                       'base as every other time in the dataset, '
                                       'not to the start of the trial'}), ...
         'visual_stimulus_left_contrast', types.hdmf_common.VectorData(...
                        'data', visual_left(:), ...
                        'description', {'Proportion contrast. A value of 0.5 '
                                        'means 50% contrast. 0 is a blank '
                                        'screen: no change to any pixel values on that '
                                        'side (completely undetectable).'}), ...
         'visual_stimulus_right_contrast', types.hdmf_common.VectorData(...
                        'data', visual_right(:), ...
                        'description', {'Times are relative to the same '
                          'time base as every other time in the dataset, '
                          'not to the start of the trial.'}), ...
         'response_time', types.hdmf_common.VectorData(...
                        'data', response_times(:), ...
                        'description', {'Enumerated type. The response registered '
                                        'at the end of the trial, '
                                        'which determines the feedback according to the contrast condition. '
                                        'Note that in a small percentage of cases (~4%, see manuscript Methods) '
                                        'the initial wheel turn was in the opposite direction. -1 for Right '
                                        'choice (i.e. correct when stimuli are on the right); +1 for left '
                                        'choice; 0 for Nogo choice.'}), ...
        'response_choice', types.hdmf_common.VectorData(...
                        'data', response_choice(:), ...
                        'description', {'Enumerated type. The response '
                        'registered at the end of the trial, '
                        'which determines the feedback according to the contrast condition. '
                        'Note that in a small percentage of cases (~4%, see manuscript Methods) '
                        'the initial wheel turn was in the opposite direction. -1 for Right '
                        'choice (i.e. correct when stimuli are on the right); +1 for left '
                        'choice; 0 for Nogo choice.'}), ...
        'feedback_time', types.hdmf_common.VectorData(...
                        'data', fb_time(:), ...
                        'description', {'Times are relative to the same time '
                                        'base as every other time in the dataset, '
                                        'not to the start of the trial.'}), ...
        'feedback_type', types.hdmf_common.VectorData(...
                        'data', fb_type(:), ...
                        'description', {'Enumerated type. -1 for negative '
                                'feedback (white noise burst); +1 for '
                                'positive feedback (water reward delivery).'}), ...
        'rep_num', types.hdmf_common.VectorData(...
                        'data', rep_num(:), ...
                        'description', {'Trials are repeated if they are "easy" '
                            'trials (high contrast stimuli with large difference between '
                            'the two sides, or the blank screen condition) and '
                            'this keeps track of how many times the current '
                            'trials condition has been repeated.'}));
end

function sp_noise = SparseNoise()
    % sdds receptive field mapping task to nwb_file.stimulus
    sp_noise_pos = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_sparseNoise.positions.npy');
    sp_noise_t = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_sparseNoise.times.npy');

    sp_noise = types.core.TimeSeries(...
                'timestamps', sp_noise_t', ...
                'data', sp_noise_pos, ...
                'data_unit', 'degrees visual angle', ...
                'description', {'White squares shown on the screen with randomized '
                                'positions and timing - see manuscript Methods.'}, ...
                'comments', {'The altitude (first column) and azimuth (second column) '
                             'of the square.'});
end

function [beep_ts, click_ts, pass_l, pass_r, pass_white] = PassiveStim()
    % add passive beeps
    pass_beeps = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_passiveBeeps.times.npy');
    pb_data = ones(length(pass_beeps), 1);
    beep_ts = types.core.TimeSeries(...
                'timestamps', pass_beeps', ...
                'data', pb_data, ...
                'data_unit', 'uk', ...
                'description', {'Auditory tones of the same frequency as the auditory '
                                'tone cue in the task'});
    % passive valve clicks
    pass_clicks = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_passiveValveClick.times.npy');
    pc_data = ones(length(pass_clicks), 1);
    click_ts = types.core.TimeSeries(...
                'timestamps', pass_clicks', ...
                'data', pc_data, ...
                'data_unit', 'uk', ...
                'description', {'Opening of the reward valve, but with a clamp in place '
                                'such that no water flows. Therefore the auditory sound of '
                                'the valve is heard, but no water reward is obtained.'});

   % passive visual times
    pass_vis = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_passiveVisual.times.npy');
    pass_vis_left = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_passiveVisual.contrastLeft.npy');
    pass_vis_right = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_passiveVisual.contrastRight.npy');

    pass_l = types.core.TimeSeries(...
                'timestamps', pass_vis', ...
                'data', pass_vis_left', ...
                'data_unit', 'proportion contrast', ...
                'description', {'Gratings of the same size, spatial freq, position, etc '
                                'as during the discrimination task.'});

     pass_r = types.core.TimeSeries(...
                'timestamps', pass_vis', ...
                'data', pass_vis_right', ...
                'data_unit', 'proportion contrast', ...
                'description', {'Gratings of the same size, spatial freq, position, etc '
                                'as during the discrimination task.'});

    % passive valve clicks
    pass_noise = readNPY('nicklab_Subjects_Hench_2017-06-15_001_alf_passiveWhiteNoise.times.npy');
    pc_data = ones(length(pass_noise), 1);
    pass_white = types.core.TimeSeries(...
                'timestamps', pass_noise', ...
                'data', pc_data, ...
                'data_unit', 'uk', ...
                'description', {'The sound that accompanies an incorrect response during the '
                                'discrimination task.'});
end

function [nwb_file, electrode_groups] = ElectrodeTable(nwb_file)
    % add channel information to electrode table
    probe_descriptions = tdfread('nicklab_Subjects_Cori_2016-12-14_001_alf_probes.description.tsv', '\t');
    electrode_groups = [];
    for p = 1:size(probe_descriptions.description, 1)
        probe_device = types.core.Device();
        probe_elec_grp = types.core.ElectrodeGroup(...
                                'description', 'Neuropixels Phase3A opt3', ...
                                'device', probe_device, ...
                                'location', 'unknown');
        electrode_groups = [electrode_groups, probe_elec_grp];
    end
    % add channel information to electrode table
    insertion_df = tdfread('nicklab_Subjects_Cori_2016-12-14_001_alf_probes.insertion.tsv', '\t');
    insertion_df.group_name = (0:length(insertion_df.entry_point_rl)-1)';
    channel_site = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~channels.site.npy');
    channel_brain = tdfread('nicklab~Subjects~Cori~2016-12-14~001~alf~channels.brainLocation.tsv', '\t');
    channel_probes = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~channels.probe.npy');
    channel_probes = ceil(channel_probes(:));

    columns = {'group_name', 'entry_point_rl', 'entry_point_ap', ...
               'vertical_angle', 'horizontal_angle', 'axial_angle', ...
               'distance_advanced'};
    channel_table = struct('group_name', channel_probes);

    channel_table = join(struct2table(channel_table), struct2table(insertion_df), 'Keys', 'group_name');

    entry_point_rl = channel_table.entry_point_rl;
    entry_point_ap = channel_table.entry_point_ap;
    axial_angle = channel_table.axial_angle;
    vertical_angle = channel_table.vertical_angle;
    horizontal_angle = channel_table.horizontal_angle;
    distance_advanced = channel_table.distance_advanced;

    locations = channel_brain.allen_ontology;
    groups = electrode_groups(channel_probes + 1)';

    channel_sitepos = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~channels.sitePositions.npy');

    columns = {'x', 'y', 'z', 'imp', 'location', 'filtering', ...
               'site_id', 'site_position', 'ccf_ap', 'ccf_dv', 'ccf_lr', ...
               'entry_point_rl', 'entry_point_ap', 'vertical_angle', ...
               'horizontal_angle', 'axial_angle', 'distance_advanced'};

    x = nan(size(groups, 1), 1);
    y = nan(size(groups, 1), 1);
    z = nan(size(groups, 1), 1);
    imp = nan(size(groups, 1), 1);
    filtering = repmat('none', size(groups, 1), 1);

    electrode_tbl = table(x, y, z, imp, locations, filtering, ...
               channel_site, channel_sitepos, channel_brain.ccf_ap, ...
               channel_brain.ccf_dv, channel_brain.ccf_lr, ...
               entry_point_rl, entry_point_ap, vertical_angle, ...
               horizontal_angle, axial_angle, distance_advanced, ...
               'VariableNames', columns);
    electrode_tbl = util.table2nwb(electrode_tbl, 'all electrodes');
    nwb_file.general_extracellular_ephys_electrodes = electrode_tbl;
end

function nwb_file = ClustersSpikes(nwb_file, electrode_groups)
    % add clusters and spikes
    cluster_probe = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~clusters.probes.npy');
    cluster_probe = ceil(cluster_probe(:));
    cluster_channel = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~clusters.peakChannel.npy');
    cluster_depths = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~clusters.depths.npy');
    phy_annotations = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~clusters._phy_annotation.npy');
    phy_annotations = phy_annotations(:);
    waveform_chans = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~clusters.templateWaveformChans.npy');
    waveform_chans = ceil(waveform_chans);
    waveform = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~clusters.templateWaveforms.npy');
    waveform_duration = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~clusters.waveformDuration.npy');
    spike_to_clusters = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~spikes.clusters.npy');
    spike_times = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~spikes.times.npy');
    spike_amps = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~spikes.amps.npy');
    spike_depths = readNPY('nicklab~Subjects~Cori~2016-12-14~001~alf~spikes.depths.npy');

    cluster_info = unique((spike_to_clusters));

    clusters = cell(1, size(cluster_info, 1));

    for i = 1:size(spike_to_clusters, 1)
        s = ceil(spike_to_clusters(i));
        if isempty(clusters{s+1})
            clusters{s+1} = [];
        end
        clusters{s+1}{end+1} = i;
    end

    times = cell(size(clusters', 1), 1);
    annotations = cell(size(clusters', 1), 1);
    channel = cell(size(clusters', 1), 1);
    duration = cell(size(clusters', 1), 1);
    elec_grps = cell(size(clusters', 1), 1);
    amps = cell(size(clusters', 1), 1);
    depths = cell(size(clusters', 1), 1);
    for i = 1:size(clusters', 1)
        times{i} = spike_times(cell2mat(clusters{i}'));
        annotations{i} = ceil(phy_annotations(i));
        channel{i} = ceil(cluster_channel(i));
        duration{i} = ceil(waveform_duration(i));
        elec_grps{i} = electrode_groups(cluster_probe(i)+1);
        amps{i} = spike_amps(i);
        depths{i} = spike_depths(i);
    end

    id = types.hdmf_common.ElementIdentifiers('data', int64(0:length(clusters)-1));
    columns = {'spike_times', 'phy_annotations', 'peak_channel', ...
           'waveform_duration', 'cluster_depths', 'sampling_rate', ...
           'spike_amps', 'spike_depths'};

    [spike_times_vector, spike_times_index] = util.create_indexed_column( ...
                                            times, '/units/spike_times', ...
                                            'description', 'spikes data');
    nwb_file.units = types.core.Units( ...
        'colnames', columns, ...
        'description', 'Units table', ...
        'id', id, ...
        'spike_times', spike_times_vector, ...
        'spike_times_index', spike_times_index, ...
        'electrode_group', types.hdmf_common.VectorData('data', elec_grps, ...
                        'description',{'Electrode group'}), ...
        'electrodes', types.hdmf_common.DynamicTableRegion('data', waveform_chans), ...
        'waveform_mean', types.hdmf_common.VectorData('data', waveform, ...
                        'description',{'Waveform mean'}), ...
        'peak_channel', types.hdmf_common.VectorData('data', channel, ...
                        'description',{'The channel number of the location of '
                        'the peak of the cluster waveform.'}), ...
        'waveform_duration', types.hdmf_common.VectorData('data', duration, ...
                        'description',{'The trough-to-peak duration of '
                        'the waveform on the peak channel'}), ...
        'phy_annotations', types.hdmf_common.VectorData('data', annotations, ...
                'description',{'0 = noise (these are already excluded and dont appear in this dataset '
                'at all); 1 = MUA (i.e. presumed to contain spikes from multiple neurons; '
                'these are not analyzed in any analyses in the paper); 2 = Good (manually '
                'labeled); 3 = Unsorted. In this dataset Good was applied in a few but '
                'not all datasets to included neurons, so in general the neurons with '
                '_phy_annotation>=2 are the ones that should be included.'}), ...
        'cluster_depths', types.hdmf_common.VectorData('data', cluster_depths, ...
                    'description',{'The position of the center of mass of the template of the cluster, '
                    'relative to the probe. The deepest channel on the probe is depth=0, '
                    'and the most superficial is depth=3820. Units: Âµm'}), ...
        'sampling_rate', types.hdmf_common.VectorData('data', ...
                        repmat(30000.0, length(cluster_info), 1), ...
                        'description',{'Sampling rate in Hz'}), ...
        'spike_amps', types.hdmf_common.VectorData('data', amps, ...
                        'description',{'The peak-to-trough amplitude, '
                                        'obtained from the template and '
                                        'template-scaling amplitude returned by Kilosort '
                                        '(not from the raw data).'}), ...
        'spike_depths', types.hdmf_common.VectorData('data', depths, ...
                        'description',{'The position of the center of mass '
                            'of the spike on the probe, '
                            'determined from the principal component features '
                            'returned by Kilosort. '
                            'The deepest channel on the probe is depth=0, '
                            'and the most superficial is depth=3820.'}));
end
